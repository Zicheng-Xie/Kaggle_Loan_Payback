{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7c297c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-07T04:21:04.743423Z",
     "iopub.status.busy": "2025-11-07T04:21:04.743097Z",
     "iopub.status.idle": "2025-11-07T04:21:06.773715Z",
     "shell.execute_reply": "2025-11-07T04:21:06.772537Z"
    },
    "papermill": {
     "duration": 2.038024,
     "end_time": "2025-11-07T04:21:06.775377",
     "exception": false,
     "start_time": "2025-11-07T04:21:04.737353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/playground-series-s5e11/sample_submission.csv\n",
      "/kaggle/input/playground-series-s5e11/train.csv\n",
      "/kaggle/input/playground-series-s5e11/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011acffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T04:21:06.783357Z",
     "iopub.status.busy": "2025-11-07T04:21:06.782950Z",
     "iopub.status.idle": "2025-11-07T04:21:16.339235Z",
     "shell.execute_reply": "2025-11-07T04:21:16.338207Z"
    },
    "papermill": {
     "duration": 9.56207,
     "end_time": "2025-11-07T04:21:16.340870",
     "exception": false,
     "start_time": "2025-11-07T04:21:06.778800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86568777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T04:21:16.348365Z",
     "iopub.status.busy": "2025-11-07T04:21:16.347765Z",
     "iopub.status.idle": "2025-11-07T04:21:16.363778Z",
     "shell.execute_reply": "2025-11-07T04:21:16.362911Z"
    },
    "papermill": {
     "duration": 0.021271,
     "end_time": "2025-11-07T04:21:16.365267",
     "exception": false,
     "start_time": "2025-11-07T04:21:16.343996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, warnings, gc, math, random\n",
    "import numpy as np, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be582b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T04:21:16.372420Z",
     "iopub.status.busy": "2025-11-07T04:21:16.372127Z",
     "iopub.status.idle": "2025-11-07T04:21:16.376655Z",
     "shell.execute_reply": "2025-11-07T04:21:16.375966Z"
    },
    "papermill": {
     "duration": 0.009588,
     "end_time": "2025-11-07T04:21:16.378023",
     "exception": false,
     "start_time": "2025-11-07T04:21:16.368435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------- Utils\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed); os.environ[\"PYTHONHASHSEED\"]=str(seed)\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2519e9ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T04:21:16.385205Z",
     "iopub.status.busy": "2025-11-07T04:21:16.384910Z",
     "iopub.status.idle": "2025-11-07T04:21:18.658245Z",
     "shell.execute_reply": "2025-11-07T04:21:18.657501Z"
    },
    "papermill": {
     "duration": 2.278754,
     "end_time": "2025-11-07T04:21:18.659759",
     "exception": false,
     "start_time": "2025-11-07T04:21:16.381005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: /kaggle/input/playground-series-s5e11\n"
     ]
    }
   ],
   "source": [
    "# --------------- Locate dataset dir (train.csv, test.csv, sample_submission.csv)\n",
    "def find_data_dir(root=\"/kaggle/input\"):\n",
    "    cands = []\n",
    "    for d, _, files in os.walk(root):\n",
    "        fs = set(files)\n",
    "        if {\"train.csv\",\"test.csv\",\"sample_submission.csv\"}.issubset(fs):\n",
    "            cands.append(d)\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"Cannot find dataset folder with train/test/sample_submission.\")\n",
    "    return sorted(cands, key=len)[0]\n",
    "\n",
    "DATA_DIR = find_data_dir()\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "test  = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "sub   = pd.read_csv(f\"{DATA_DIR}/sample_submission.csv\")\n",
    "\n",
    "TARGET = \"loan_paid_back\" if \"loan_paid_back\" in train.columns else \"target\"\n",
    "ID_COL = \"id\" if \"id\" in train.columns else train.columns[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50662a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T04:21:18.666916Z",
     "iopub.status.busy": "2025-11-07T04:21:18.666598Z",
     "iopub.status.idle": "2025-11-07T04:21:19.968447Z",
     "shell.execute_reply": "2025-11-07T04:21:19.967102Z"
    },
    "papermill": {
     "duration": 1.307548,
     "end_time": "2025-11-07T04:21:19.970478",
     "exception": false,
     "start_time": "2025-11-07T04:21:18.662930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------------- Basic cleaning\n",
    "# Drop perfect duplicates in train (keep first)\n",
    "if train.duplicated().any():\n",
    "    train = train.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Identify dtypes\n",
    "num_cols = [c for c in train.columns if c not in [TARGET, ID_COL] and pd.api.types.is_numeric_dtype(train[c])]\n",
    "cat_cols = [c for c in train.columns if c not in [TARGET, ID_COL] and not pd.api.types.is_numeric_dtype(train[c])]# Also treat low-cardinality numerics as categories (robust to int-coded categories)\n",
    "for c in num_cols.copy():\n",
    "    if train[c].nunique() <= 12 and train[c].dtype != float:  # small buckets → likely categorical\n",
    "        cat_cols.append(c); num_cols.remove(c)\n",
    "\n",
    "\n",
    "# Align test columns\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].astype(\"category\")\n",
    "    test[c]  = test[c].astype(\"category\")\n",
    "\n",
    "# Missing handling\n",
    "for c in num_cols:\n",
    "    med = train[c].median()\n",
    "    train[c] = train[c].fillna(med)\n",
    "    test[c]  = test[c].fillna(med)\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].cat.add_categories([\"__MISSING__\"]).fillna(\"__MISSING__\")\n",
    "    test[c]  = test[c].cat.add_categories([\"__MISSING__\"]).fillna(\"__MISSING__\")\n",
    "    \n",
    "    # Clip outliers (1% - 99%)\n",
    "for c in num_cols:\n",
    "    lo, hi = train[c].quantile(0.01), train[c].quantile(0.99)\n",
    "    train[c] = train[c].clip(lo, hi)\n",
    "    test[c]  = test[c].clip(lo, hi)\n",
    "    \n",
    "    # --------------- Finance-inspired automatic features (created only if source cols exist)\n",
    "def add_finance_features(df):\n",
    "    cols = df.columns\n",
    "    def pick(name): \n",
    "        return [c for c in cols if name in c]\n",
    "    # Heuristic picks\n",
    "    inc  = pick(\"income\") or pick(\"salary\")\n",
    "    amt  = pick(\"loan_amount\") or pick(\"amount\")\n",
    "    rate = pick(\"interest_rate\") or pick(\"rate\")\n",
    "    debt = pick(\"debt\") + pick(\"debt_to_income\")\n",
    "    score= pick(\"credit_score\") or pick(\"score\")\n",
    "\n",
    "    if inc and amt:\n",
    "        a, i = amt[0], inc[0]\n",
    "        df[\"loan_to_income\"] = (df[a] / (df[i].replace(0, np.nan))).fillna(0)\n",
    "        df[\"log_income\"]     = np.log1p(df[i])\n",
    "        df[\"log_amount\"]     = np.log1p(df[a])\n",
    "\n",
    "    if inc and amt and rate:\n",
    "        a, i, r = amt[0], inc[0], rate[0]\n",
    "        df[\"interest_burden\"] = (df[a] * df[r]) / (df[i].replace(0, np.nan))\n",
    "        df[\"interest_burden\"] = df[\"interest_burden\"].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    if score:\n",
    "        s = score[0]\n",
    "        # quantile buckets as risk tiers\n",
    "        df[\"credit_tier\"] = pd.qcut(df[s].rank(method=\"first\"), q=10, labels=False, duplicates=\"drop\").astype(\"int16\")\n",
    "\n",
    "    if debt:\n",
    "        d = debt[0]\n",
    "        df[\"debt_ratio_logit\"] = np.log1p(df[d] / (1 - np.clip(df[d], 1e-6, 1-1e-6))) if df[d].max()<=1.0 else np.log1p(df[d])\n",
    "\n",
    "    return df\n",
    "\n",
    "train = add_finance_features(train)\n",
    "test  = add_finance_features(test)\n",
    "\n",
    "# Update dtypes after feature add\n",
    "new_num = [c for c in train.columns if c not in [TARGET, ID_COL] and pd.api.types.is_numeric_dtype(train[c])]\n",
    "new_cat = [c for c in train.columns if c not in [TARGET, ID_COL] and not pd.api.types.is_numeric_dtype(train[c])]\n",
    "for c in new_cat:\n",
    "    train[c] = train[c].astype(\"category\"); test[c] = test[c].astype(\"category\")\n",
    "num_cols, cat_cols = new_num, new_cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8757c303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T04:21:19.979406Z",
     "iopub.status.busy": "2025-11-07T04:21:19.979099Z",
     "iopub.status.idle": "2025-11-07T04:23:03.253945Z",
     "shell.execute_reply": "2025-11-07T04:23:03.252939Z"
    },
    "papermill": {
     "duration": 103.281194,
     "end_time": "2025-11-07T04:23:03.255778",
     "exception": false,
     "start_time": "2025-11-07T04:21:19.974584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 475195, number of negative: 203655\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2594\n",
      "[LightGBM] [Info] Number of data points in the train set: 678850, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.700000 -> initscore=0.847298\n",
      "[LightGBM] [Info] Start training from score 0.847298\n",
      "[LightGBM] [Info] Number of positive: 475195, number of negative: 203655\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2593\n",
      "[LightGBM] [Info] Number of data points in the train set: 678850, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.700000 -> initscore=0.847298\n",
      "[LightGBM] [Info] Start training from score 0.847298\n",
      "[LightGBM] [Info] Number of positive: 475195, number of negative: 203655\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2592\n",
      "[LightGBM] [Info] Number of data points in the train set: 678850, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.700000 -> initscore=0.847298\n",
      "[LightGBM] [Info] Start training from score 0.847298\n",
      "[LightGBM] [Info] Number of positive: 475195, number of negative: 203656\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2595\n",
      "[LightGBM] [Info] Number of data points in the train set: 678851, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.699999 -> initscore=0.847293\n",
      "[LightGBM] [Info] Start training from score 0.847293\n",
      "[LightGBM] [Info] Number of positive: 475196, number of negative: 203655\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2590\n",
      "[LightGBM] [Info] Number of data points in the train set: 678851, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.700000 -> initscore=0.847300\n",
      "[LightGBM] [Info] Start training from score 0.847300\n",
      "Computed adversarial sample weights.\n"
     ]
    }
   ],
   "source": [
    "# --------------- Adversarial Validation: train vs test shift → sample weights\n",
    "def adversarial_weights(train_df, test_df, num_cols, cat_cols, seed=SEED):\n",
    "    tmp_tr = train_df[[ID_COL] + num_cols + cat_cols].copy(); tmp_tr[\"is_train\"] = 1\n",
    "    tmp_te = test_df [[ID_COL] + num_cols + cat_cols].copy(); tmp_te[\"is_train\"] = 0\n",
    "    ad = pd.concat([tmp_tr, tmp_te], axis=0, ignore_index=True)\n",
    "\n",
    "    # Encode cats with LabelEncoder (CatBoost can handle cats but here we want a simple LGBM)\n",
    "    ad_enc = ad.copy()\n",
    "    encoders = {}\n",
    "    for c in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        ad_enc[c] = le.fit_transform(ad_enc[c].astype(str))\n",
    "        encoders[c] = le\n",
    "\n",
    "    feats = num_cols + cat_cols\n",
    "    y_ad = ad_enc[\"is_train\"].values\n",
    "    X_ad = ad_enc[feats].values\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros(len(ad_enc))\n",
    "    for tr_idx, va_idx in skf.split(X_ad, y_ad):\n",
    "        model = LGBMClassifier(\n",
    "            n_estimators=400,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=-1,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=seed, objective=\"binary\",\n",
    "            min_child_samples=60\n",
    "        )\n",
    "        # >>> 删除 verbose 参数，其他不变\n",
    "        model.fit(\n",
    "            X_ad[tr_idx], y_ad[tr_idx],\n",
    "            eval_set=[(X_ad[va_idx], y_ad[va_idx])],\n",
    "            eval_metric=\"auc\"\n",
    "        )\n",
    "        oof[va_idx] = model.predict_proba(X_ad[va_idx])[:, 1]\n",
    "\n",
    "    # Probability of being train-sourced\n",
    "    p_train = oof[:len(train_df)]\n",
    "    # Higher prob(train) → downweight, using inverse propensity\n",
    "    eps = 1e-3\n",
    "    w = (1 - p_train + eps) / (p_train + eps)\n",
    "    w = np.clip(w / np.mean(w), 0.25, 4.0)  # stabilized\n",
    "    return w\n",
    "    \n",
    "    \n",
    "    # --------------- Monotonic constraints for LGBM (numeric only)\n",
    "# Spearman sign wrt target; categorical set to 0\n",
    "def spearman_sign(x, y):\n",
    "    return np.sign(pd.Series(x).rank().corr(pd.Series(y), method=\"spearman\") or 0.0)\n",
    "\n",
    "y = train[TARGET].values\n",
    "mono_map = {}\n",
    "for c in num_cols:\n",
    "    mono_map[c] = int(spearman_sign(train[c].values, y))\n",
    "    \n",
    "  # Monotonic constraints (numeric only, by Spearman sign)\n",
    "# =========================\n",
    "def spearman_sign(x, y):\n",
    "    return int(np.sign(pd.Series(x).rank().corr(pd.Series(y), method=\"spearman\") or 0.0))\n",
    "\n",
    "y = train[TARGET].values\n",
    "mono_map = {c: spearman_sign(train[c].values, y) for c in num_cols}\n",
    "\n",
    "features_order = num_cols + cat_cols\n",
    "lgb_mono = [mono_map.get(c, 0) if c in num_cols else 0 for c in features_order]\n",
    "\n",
    "\n",
    "# ============== 继续：计算对抗验证权重 ==============\n",
    "# 若失败则回退为等权，避免 NameError\n",
    "try:\n",
    "    sample_weights = adversarial_weights(train, test, num_cols, cat_cols, seed=SEED)\n",
    "    print(\"Computed adversarial sample weights.\")\n",
    "except Exception as e:\n",
    "    print(\"Adversarial weighting failed → using uniform weights. Reason:\", e)\n",
    "    sample_weights = np.ones(len(train), dtype=float)\n",
    "\n",
    "# 对齐长度以防错位\n",
    "sample_weights = np.asarray(pd.Series(sample_weights).reset_index(drop=True))\n",
    "if len(sample_weights) != len(train):\n",
    "    print(\"Sample weights length mismatch; using uniform weights.\")\n",
    "    sample_weights = np.ones(len(train), dtype=float)\n",
    "    \n",
    "   # ============== 单调约束：按 Spearman 方向 ==============\n",
    "y = train[TARGET].values\n",
    "def spearman_sign(x, y):\n",
    "    return int(np.sign(pd.Series(x).rank().corr(pd.Series(y), method=\"spearman\") or 0.0))\n",
    "\n",
    "mono_map = {c: spearman_sign(train[c].values, y) for c in num_cols}\n",
    "\n",
    "features_order = num_cols + cat_cols\n",
    "# LightGBM 需要与特征顺序等长的约束向量；非数值特征置 0（不约束）\n",
    "lgb_mono = [mono_map.get(c, 0) if c in num_cols else 0 for c in features_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1a8993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T04:23:03.265938Z",
     "iopub.status.busy": "2025-11-07T04:23:03.265512Z",
     "iopub.status.idle": "2025-11-07T06:07:58.860021Z",
     "shell.execute_reply": "2025-11-07T06:07:58.858597Z"
    },
    "papermill": {
     "duration": 6295.601661,
     "end_time": "2025-11-07T06:07:58.861923",
     "exception": false,
     "start_time": "2025-11-07T04:23:03.260262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[462]\tvalid_0's auc: 0.915834\tvalid_0's binary_logloss: 0.253156\n",
      "Fold 1: AUC CatBoost=0.92061 | LGBM=0.91583\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[436]\tvalid_0's auc: 0.914849\tvalid_0's binary_logloss: 0.254564\n",
      "Fold 2: AUC CatBoost=0.92041 | LGBM=0.91485\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[441]\tvalid_0's auc: 0.913647\tvalid_0's binary_logloss: 0.255545\n",
      "Fold 3: AUC CatBoost=0.91876 | LGBM=0.91365\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's auc: 0.914538\tvalid_0's binary_logloss: 0.254004\n",
      "Fold 4: AUC CatBoost=0.91959 | LGBM=0.91454\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[461]\tvalid_0's auc: 0.914379\tvalid_0's binary_logloss: 0.253077\n",
      "Fold 5: AUC CatBoost=0.91911 | LGBM=0.91438\n",
      "\n",
      "OOF AUC - CatBoost: 0.91969 | LGBM: 0.91464\n"
     ]
    }
   ],
   "source": [
    "# ============== 交叉验证训练：CatBoost + LightGBM（单调） ==============\n",
    "FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "oof_cb  = np.zeros(len(train))\n",
    "oof_lgb = np.zeros(len(train))\n",
    "pred_cb  = np.zeros(len(test))\n",
    "pred_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(train[features_order], train[TARGET])):\n",
    "    X_tr, X_va = train.iloc[tr_idx][features_order], train.iloc[va_idx][features_order]\n",
    "    y_tr, y_va = train.iloc[tr_idx][TARGET],      train.iloc[va_idx][TARGET]\n",
    "    w_tr = sample_weights[tr_idx]\n",
    "\n",
    "    # ---- CatBoost（原生类别）\n",
    "    pool_tr = Pool(X_tr, y_tr, cat_features=[features_order.index(c) for c in cat_cols], weight=w_tr)\n",
    "    pool_va = Pool(X_va, y_va, cat_features=[features_order.index(c) for c in cat_cols])\n",
    "\n",
    "    cb = CatBoostClassifier(\n",
    "        iterations=3000,\n",
    "        learning_rate=0.03,\n",
    "        depth=6,\n",
    "        eval_metric=\"AUC\",\n",
    "        loss_function=\"Logloss\",\n",
    "        l2_leaf_reg=3.0,\n",
    "        random_state=SEED,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=200,\n",
    "        border_count=128,\n",
    "        task_type=\"CPU\"\n",
    "    )\n",
    "    cb.fit(pool_tr, eval_set=pool_va, verbose=False)\n",
    "    oof_cb[va_idx] = cb.predict_proba(pool_va)[:, 1]\n",
    "    pred_cb += cb.predict_proba(Pool(test[features_order], cat_features=[features_order.index(c) for c in cat_cols]))[:, 1] / FOLDS\n",
    "\n",
    "    # ---- LightGBM（单调约束 + 早停 + 静默）\n",
    "    lgb = LGBMClassifier(\n",
    "        n_estimators=6000,\n",
    "        learning_rate=0.015,\n",
    "        num_leaves=64,\n",
    "        max_depth=-1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.85,\n",
    "        min_child_samples=80,\n",
    "        reg_alpha=1.0, reg_lambda=2.0,\n",
    "        objective=\"binary\",\n",
    "        random_state=SEED,\n",
    "        monotone_constraints=lgb_mono,   # 注意逗号\n",
    "        force_row_wise=True,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    lgb.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric=\"auc\",\n",
    "        categorical_feature=cat_cols,\n",
    "        sample_weight=w_tr,\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=300),  # 300 轮无提升即停\n",
    "            log_evaluation(period=0)              # 关闭逐轮打印\n",
    "        ]\n",
    "    )\n",
    "    oof_lgb[va_idx] = lgb.predict_proba(X_va)[:, 1]\n",
    "    pred_lgb += lgb.predict_proba(test[features_order])[:, 1] / FOLDS\n",
    "\n",
    "    auc_cb  = roc_auc_score(y_va, oof_cb[va_idx])\n",
    "    auc_lgb = roc_auc_score(y_va, oof_lgb[va_idx])\n",
    "    print(f\"Fold {fold+1}: AUC CatBoost={auc_cb:.5f} | LGBM={auc_lgb:.5f}\")\n",
    "\n",
    "auc_cb  = roc_auc_score(train[TARGET], oof_cb)\n",
    "auc_lgb = roc_auc_score(train[TARGET], oof_lgb)\n",
    "print(f\"\\nOOF AUC - CatBoost: {auc_cb:.5f} | LGBM: {auc_lgb:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e6b5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:07:58.871893Z",
     "iopub.status.busy": "2025-11-07T06:07:58.871516Z",
     "iopub.status.idle": "2025-11-07T06:07:59.587861Z",
     "shell.execute_reply": "2025-11-07T06:07:59.586737Z"
    },
    "papermill": {
     "duration": 0.72306,
     "end_time": "2025-11-07T06:07:59.589395",
     "exception": false,
     "start_time": "2025-11-07T06:07:58.866335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blend Weights → CatBoost: 0.501, LGBM: 0.499\n",
      "OOF AUC (Blend): 0.9180598940429525\n",
      "OOF AUC (Calibrated): 0.9181680548120736\n"
     ]
    }
   ],
   "source": [
    "# ============== 融合 + 概率校准（Isotonic） ==============\n",
    "w_cb  = auc_cb  / (auc_cb + auc_lgb + 1e-9)\n",
    "w_lgb = auc_lgb / (auc_cb + auc_lgb + 1e-9)\n",
    "print(f\"Blend Weights → CatBoost: {w_cb:.3f}, LGBM: {w_lgb:.3f}\")\n",
    "\n",
    "oof_blend  = w_cb * oof_cb + w_lgb * oof_lgb\n",
    "pred_blend = w_cb * pred_cb + w_lgb * pred_lgb\n",
    "print(\"OOF AUC (Blend):\", roc_auc_score(train[TARGET], oof_blend))\n",
    "\n",
    "cal = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "cal.fit(oof_blend, train[TARGET])\n",
    "oof_cal = cal.transform(oof_blend)\n",
    "pred_cal = cal.transform(pred_blend)\n",
    "print(\"OOF AUC (Calibrated):\", roc_auc_score(train[TARGET], oof_cal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ed2afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T06:07:59.602000Z",
     "iopub.status.busy": "2025-11-07T06:07:59.601548Z",
     "iopub.status.idle": "2025-11-07T06:41:50.523670Z",
     "shell.execute_reply": "2025-11-07T06:41:50.522760Z"
    },
    "papermill": {
     "duration": 2030.930153,
     "end_time": "2025-11-07T06:41:50.525080",
     "exception": false,
     "start_time": "2025-11-07T06:07:59.594927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotonic calibration done.\n",
      "Pseudo-labeled rows: 42262\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's auc: 0.9214\tvalid_0's binary_logloss: 0.244493\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's auc: 0.920758\tvalid_0's binary_logloss: 0.245462\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's auc: 0.919524\tvalid_0's binary_logloss: 0.246887\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's auc: 0.920533\tvalid_0's binary_logloss: 0.24512\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's auc: 0.920725\tvalid_0's binary_logloss: 0.24377\n",
      "OOF AUC (Aug LGBM): 0.9205868074165878\n",
      "Saved submission.csv with shape: (254569, 2)\n",
      "\n",
      "=== QUICK REPORT ===\n",
      "Train shape: (593994, 19) | Test shape: (254569, 18)\n",
      "Target positive rate: 0.7988\n",
      "Cat cols: 6 | Num cols: 11 | Total feats: 17\n"
     ]
    }
   ],
   "source": [
    "# ============== 高置信伪标签 + 精简 LGBM 再训练（自洽兜底 v2） ==============\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 若缺少 blend，则尝试重建\n",
    "if ('oof_blend' not in locals()) or ('pred_blend' not in locals()):\n",
    "    built = False\n",
    "    if ('oof_cb' in locals()) and ('oof_lgb' in locals()) and ('pred_cb' in locals()) and ('pred_lgb' in locals()):\n",
    "        if 'auc_cb' not in locals():\n",
    "            auc_cb = roc_auc_score(train[TARGET], oof_cb)\n",
    "        if 'auc_lgb' not in locals():\n",
    "            auc_lgb = roc_auc_score(train[TARGET], oof_lgb)\n",
    "        w_cb  = auc_cb / (auc_cb + auc_lgb + 1e-9)\n",
    "        w_lgb = 1.0 - w_cb\n",
    "        oof_blend  = w_cb * oof_cb  + w_lgb * oof_lgb\n",
    "        pred_blend = w_cb * pred_cb + w_lgb * pred_lgb\n",
    "        print(\"Rebuilt oof_blend/pred_blend using OOF AUC weights.\")\n",
    "        built = True\n",
    "    else:\n",
    "        # 只有 test 预测时的回退\n",
    "        if ('pred_cb' in locals()) and ('pred_lgb' in locals()):\n",
    "            pred_blend = 0.5 * pred_cb + 0.5 * pred_lgb\n",
    "            oof_blend  = None\n",
    "            print(\"Built pred_blend from test preds only (no OOF available).\")\n",
    "        elif 'pred_lgb' in locals():\n",
    "            pred_blend = pred_lgb; oof_blend = None; print(\"Using LGBM test preds only.\")\n",
    "        elif 'pred_cb' in locals():\n",
    "            pred_blend = pred_cb;  oof_blend = None; print(\"Using CatBoost test preds only.\")\n",
    "        else:\n",
    "            raise RuntimeError(\"No predictions found. Please run the CV training cell first.\")\n",
    "\n",
    "# 概率校准（若无 OOF 则跳过）\n",
    "try:\n",
    "    if oof_blend is not None:\n",
    "        cal = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "        cal.fit(oof_blend, train[TARGET])\n",
    "        oof_cal = cal.transform(oof_blend)\n",
    "        pred_cal = cal.transform(pred_blend)\n",
    "        print(\"Isotonic calibration done.\")\n",
    "    else:\n",
    "        raise ValueError(\"No OOF to calibrate.\")\n",
    "except Exception as e:\n",
    "    print(\"Calibration skipped → using uncalibrated blend. Reason:\", e)\n",
    "    oof_cal = oof_blend if 'oof_blend' in locals() else None\n",
    "    pred_cal = pred_blend\n",
    "\n",
    "# 选择高置信样本做伪标签；若太少自动放宽阈值；若仍无则跳过伪标签\n",
    "hi_pos = (pred_cal >= 0.99)\n",
    "hi_neg = (pred_cal <= 0.01)\n",
    "pseudo = test.loc[hi_pos | hi_neg, features_order].copy()\n",
    "\n",
    "if pseudo.shape[0] == 0:\n",
    "    print(\"No high-confidence rows at 0.99/0.01 → try 0.98/0.02.\")\n",
    "    hi_pos = (pred_cal >= 0.98)\n",
    "    hi_neg = (pred_cal <= 0.02)\n",
    "    pseudo = test.loc[hi_pos | hi_neg, features_order].copy()\n",
    "\n",
    "if pseudo.shape[0] == 0:\n",
    "    print(\"Still none; skip pseudo-label stage.\")\n",
    "    final_pred = pred_cal\n",
    "    out = sub.copy()\n",
    "    out[out.columns[-1]] = final_pred\n",
    "    out.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Saved submission.csv (no pseudo-labeling).\")\n",
    "else:\n",
    "    pseudo[TARGET] = (pred_cal[hi_pos | hi_neg] > 0.5).astype(int)\n",
    "    print(f\"Pseudo-labeled rows: {len(pseudo)}\")\n",
    "\n",
    "    aug = pd.concat([train[features_order + [TARGET]], pseudo], ignore_index=True)\n",
    "    oof_aug = np.zeros(len(train))\n",
    "    pred_aug = np.zeros(len(test))\n",
    "\n",
    "    # 若 skf 未定义则补一个\n",
    "    if 'skf' not in locals():\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(train[features_order], train[TARGET])):\n",
    "        X_tr2 = aug[features_order]; y_tr2 = aug[TARGET]\n",
    "        X_va2 = train.iloc[va_idx][features_order]; y_va2 = train.iloc[va_idx][TARGET]\n",
    "\n",
    "        lgb2 = LGBMClassifier(\n",
    "            n_estimators=4000, learning_rate=0.02, num_leaves=96,\n",
    "            subsample=0.85, colsample_bytree=0.9, min_child_samples=60,\n",
    "            reg_alpha=0.5, reg_lambda=1.5, objective=\"binary\",\n",
    "            random_state=SEED+7, monotone_constraints=lgb_mono,\n",
    "            force_row_wise=True, verbosity=-1\n",
    "        )\n",
    "        lgb2.fit(\n",
    "            X_tr2, y_tr2,\n",
    "            eval_set=[(X_va2, y_va2)],\n",
    "            eval_metric=\"auc\",\n",
    "            categorical_feature=cat_cols,\n",
    "            callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=0)]\n",
    "        )\n",
    "        oof_aug[va_idx] = lgb2.predict_proba(X_va2)[:, 1]\n",
    "        pred_aug += lgb2.predict_proba(test[features_order])[:, 1] / 5\n",
    "\n",
    "    print(\"OOF AUC (Aug LGBM):\", roc_auc_score(train[TARGET], oof_aug))\n",
    "\n",
    "    w_base = 0.6\n",
    "    final_pred = w_base * pred_cal + (1 - w_base) * pred_aug\n",
    "\n",
    "    out = sub.copy()\n",
    "    out[out.columns[-1]] = final_pred\n",
    "    out.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Saved submission.csv with shape:\", out.shape)\n",
    "\n",
    "# 简要报告\n",
    "def quick_report():\n",
    "    print(\"\\n=== QUICK REPORT ===\")\n",
    "    try:\n",
    "        print(f\"Train shape: {train.shape} | Test shape: {test.shape}\")\n",
    "        print(f\"Target positive rate: {train[TARGET].mean():.4f}\")\n",
    "        print(f\"Cat cols: {len(cat_cols)} | Num cols: {len(num_cols)} | Total feats: {len(features_order)}\")\n",
    "        if 'oof_cb' in locals():  print(f\"OOF AUC - CB:  {roc_auc_score(train[TARGET], oof_cb):.5f}\")\n",
    "        if 'oof_lgb' in locals(): print(f\"OOF AUC - LGBM:{roc_auc_score(train[TARGET], oof_lgb):.5f}\")\n",
    "        if 'oof_cal' in locals() and oof_cal is not None:\n",
    "            print(f\"Blend(cal): {roc_auc_score(train[TARGET], oof_cal):.5f}\")\n",
    "        if 'oof_aug' in locals():\n",
    "            print(f\"AugLGBM:   {roc_auc_score(train[TARGET], oof_aug):.5f}\")\n",
    "    except Exception as e:\n",
    "        print(\"Report skipped:\", e)\n",
    "quick_report()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14262372,
     "sourceId": 91722,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8452.562452,
   "end_time": "2025-11-07T06:41:52.154049",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-07T04:20:59.591597",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
